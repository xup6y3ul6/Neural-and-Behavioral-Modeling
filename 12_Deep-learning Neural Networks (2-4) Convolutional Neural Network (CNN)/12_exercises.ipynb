{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "12_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c0a2e54b1b841759ca45412380779a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e160573d049420780c69de87e4b642f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91f74f87f3be4ec094e0eab66e8be903",
              "IPY_MODEL_8cfb0c0157a54e6d80b6368378a012c9"
            ]
          }
        },
        "8e160573d049420780c69de87e4b642f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91f74f87f3be4ec094e0eab66e8be903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42363af442d84ab9b748562db1e1a392",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a89a5b3748554d9b810f51c45dcba659"
          }
        },
        "8cfb0c0157a54e6d80b6368378a012c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1476635ef8547f2ae90cb26e2074452",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:40&lt;00:00, 10322052.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_756f473eb76647b1b020dc035d7432b1"
          }
        },
        "42363af442d84ab9b748562db1e1a392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a89a5b3748554d9b810f51c45dcba659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1476635ef8547f2ae90cb26e2074452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "756f473eb76647b1b020dc035d7432b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTiBx_O0w6N1"
      },
      "source": [
        "# Neural & Behavioral Modeling - Week 12 (Exercises)\n",
        "by 林子堯 (r08227112@ntu.edu.tw)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyqtOiRYw6N2"
      },
      "source": [
        "%config IPCompleter.greedy=True \n",
        "%matplotlib inline\n",
        "from matplotlib.pyplot import *\n",
        "from IPython.display import *\n",
        "import numpy as np\n",
        "from tabulate import tabulate"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2a5d1RPw6N2",
        "outputId": "6750e9d2-8000-42b1-8b3e-7a48acd6e6c0"
      },
      "source": [
        "# Check GPU status:\n",
        "import torch as t\n",
        "print('PyTorch version:',t.__version__)\n",
        "use_cuda=t.cuda.is_available()\n",
        "if(use_cuda):\n",
        "    for i in range(t.cuda.device_count()):\n",
        "        print('Device ',i,':',t.cuda.get_device_name(i))\n",
        "    print('Current: Device ',t.cuda.current_device())\n",
        "    t.backends.cudnn.benchmark = True \n",
        "    device = t.device(\"cuda\")\n",
        "else:\n",
        "    device = t.device(\"cpu\")\n",
        "    print('No GPU')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.7.0+cu101\n",
            "Device  0 : Tesla T4\n",
            "Current: Device  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GITj7KHlw6N2"
      },
      "source": [
        "## 1 Fair Performance Evaluation (5 points)\n",
        "We often compare and assess performances of different model architectures/parameters/hyperparameters. Note that the results are differnt even if you re-run exactly the same code block. This is primarily due to a non-fixed random number seed. Please:\n",
        "\n",
        "(1) run the section 1.2 TEN times and report (a) min, (b) max, (c) mean, & (d) standard deviation of the TESTING accuracies. (3 points)\n",
        "\n",
        "(2) try to fix the random number seeds in numpy & pytorch to see if you can obtain the same results every time in the section 1.2. (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFY_Lrlxw6N2"
      },
      "source": [
        "### 1.0 CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "8c0a2e54b1b841759ca45412380779a3",
            "8e160573d049420780c69de87e4b642f",
            "91f74f87f3be4ec094e0eab66e8be903",
            "8cfb0c0157a54e6d80b6368378a012c9",
            "42363af442d84ab9b748562db1e1a392",
            "a89a5b3748554d9b810f51c45dcba659",
            "d1476635ef8547f2ae90cb26e2074452",
            "756f473eb76647b1b020dc035d7432b1"
          ]
        },
        "id": "Bw18_nuyw6N2",
        "outputId": "1d6b7098-8a3c-4af7-a10e-093ba6d242b7"
      },
      "source": [
        "# Load the dataset:\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "train_set = CIFAR10(root='.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_data = t.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_set = CIFAR10(root='.', train=False, transform=transforms.ToTensor())\n",
        "test_data = t.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c0a2e54b1b841759ca45412380779a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gGmOzfmw6N2"
      },
      "source": [
        "### 1.1 The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7we64Ysw6N2"
      },
      "source": [
        "# Make the model:\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__() # = nn.Module.__init__(self)\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # in, out, kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "        self.fc1   = nn.Linear(16*5*5, 120) \n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "    def forward(self, x): # functional expressions\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
        "        x = x.view(x.size()[0], -1) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)        \n",
        "        return x\n",
        "lenet = Net()\n",
        "lenet = lenet.to(device)\n",
        "loss_fn = t.nn.CrossEntropyLoss()\n",
        "optimizer = t.optim.Adam(lenet.parameters())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_I91Gy3w6N2"
      },
      "source": [
        "### 1.2 Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jhys_QGw6N2",
        "outputId": "13457ed1-f5e4-43c1-e121-5f2c35918a57"
      },
      "source": [
        "# Training:\n",
        "for e in range(2):\n",
        "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
        "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
        "        Y_pred = lenet(X_train)\n",
        "        loss = loss_fn(Y_pred, Y_train)\n",
        "        lenet.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()   \n",
        "        Y_pred = lenet(X_train)\n",
        "        Y_pred = t.max(Y_pred,1)[1]\n",
        "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
        "    \n",
        "# Testing on a batch:\n",
        "dataiter = iter(test_data)\n",
        "X_test, Y_test = dataiter.next() # returning a batch\n",
        "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
        "with t.no_grad():\n",
        "    Y_pred = lenet(X_test)\n",
        "    Y_pred = t.max(Y_pred,1)[1]\n",
        "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 : 0.375\n",
            "epoch  1 : 0.5625\n",
            "test : 0.521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypbX7Klw6N2"
      },
      "source": [
        "### 1.3 Your answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnVj79_DP8JK"
      },
      "source": [
        "方便起見，下方我重新將老師的範例程式包在 class 中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZtVKTCM2cuN"
      },
      "source": [
        "class Simulation:\n",
        "  def __init__(self):\n",
        "    self.train_acc = None\n",
        "    self.test_acc = None\n",
        "    self.times = None\n",
        "  \n",
        "  def run_simulation(self, times=1, random_seed=None):\n",
        "    self.train_acc, self.test_acc = np.zeros(times), np.zeros(times)\n",
        "    self.times = times\n",
        "\n",
        "    for time in range(times):   \n",
        "      if random_seed is not None:\n",
        "        t.manual_seed(random_seed)\n",
        "        t.cuda.manual_seed(random_seed)\n",
        "        t.cuda.manual_seed_all(random_seed)  # if you are using multi-GPU.\n",
        "        #np.random.seed(seed)  # Numpy module.\n",
        "        #random.seed(seed)  # Python random module.\n",
        "        #t.manual_seed(seed)\n",
        "        t.backends.cudnn.benchmark = False\n",
        "        t.backends.cudnn.deterministic = True\n",
        "        # ref: https://github.com/pytorch/pytorch/issues/7068#issuecomment-679568312\n",
        "\n",
        "      # Built model:\n",
        "      lenet = Net()\n",
        "      lenet = lenet.to(device)\n",
        "      loss_fn = t.nn.CrossEntropyLoss()\n",
        "      optimizer = t.optim.Adam(lenet.parameters())\n",
        "\n",
        "      # Training:\n",
        "      for e in range(2):\n",
        "        for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
        "          X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
        "          Y_pred = lenet(X_train)\n",
        "          loss = loss_fn(Y_pred, Y_train)\n",
        "          lenet.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()   \n",
        "          Y_pred = lenet(X_train)\n",
        "          Y_pred = t.max(Y_pred,1)[1]\n",
        "        # print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
        "      self.train_acc[time] = ((Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
        "        \n",
        "      # Testing on a batch:\n",
        "      dataiter = iter(test_data)\n",
        "      X_test, Y_test = dataiter.next() # returning a batch\n",
        "      X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
        "      with t.no_grad():\n",
        "        Y_pred = lenet(X_test)\n",
        "        Y_pred = t.max(Y_pred,1)[1]\n",
        "        # print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])\n",
        "      self.test_acc[time] = ((Y_pred==Y_test).sum().item()/Y_test.shape[0])\n",
        "\n",
        "  def print_result(self):\n",
        "    print(tabulate([['N', self.times],\n",
        "            ['Min', self.test_acc.min()], \n",
        "            ['Mean', self.test_acc.mean()],\n",
        "            ['Max', self.test_acc.max()],\n",
        "            ['Standard deviaion', self.test_acc.std()]], \n",
        "            headers=['Statistic', 'Value'], tablefmt='orgtbl'))\n",
        "      "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnmSi8y2C2DJ"
      },
      "source": [
        "下方為隨機訓練模型重複 10 次(每次的 epoch 都只有 2)，不然發現每一次的 test accuracy 都是不一樣的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBQtBQ5Y5hC9",
        "outputId": "f86d870a-48ba-4ffd-e23c-3e28fe44c035"
      },
      "source": [
        "s_random = Simulation()\n",
        "s_random.run_simulation(times = 10)\n",
        "print(s_random.test_acc)\n",
        "s_random.print_result()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.512 0.527 0.471 0.524 0.527 0.55  0.483 0.521 0.517 0.516]\n",
            "| Statistic         |     Value |\n",
            "|-------------------+-----------|\n",
            "| N                 | 10        |\n",
            "| Min               |  0.471    |\n",
            "| Mean              |  0.5148   |\n",
            "| Max               |  0.55     |\n",
            "| Standard deviaion |  0.021456 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjIxBn0QC3Rn"
      },
      "source": [
        "如果我們給予固定的 random seed 數值，就能得到相同的結果。\n",
        "\n",
        "**註：**這邊可能需要注意 PyTorch random seed 的寫法，可能需要考慮到再現同樣的結果時，不同人可能是用 CPU 或是 GPU 跑。詳細寫法可以參考：https://github.com/pytorch/pytorch/issues/7068#issuecomment-679568312"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsD-E-dsPcvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edd4a8e-8466-4151-f42e-9a4df9300c8e"
      },
      "source": [
        "s_fixed = Simulation()\n",
        "s_fixed.run_simulation(times = 10, random_seed = 6666)\n",
        "print(s_fixed.test_acc)\n",
        "s_fixed.print_result()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.547 0.547 0.547 0.547 0.547 0.547 0.547 0.547 0.547 0.547]\n",
            "| Statistic         |        Value |\n",
            "|-------------------+--------------|\n",
            "| N                 | 10           |\n",
            "| Min               |  0.547       |\n",
            "| Mean              |  0.547       |\n",
            "| Max               |  0.547       |\n",
            "| Standard deviaion |  1.11022e-16 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGLD387gw6N2"
      },
      "source": [
        "## 2 Universal Approximation Theorem (5 points)\n",
        "\n",
        "Please FAIRLY evaluate whether a deep network learns XOR more efficiently than a shallow network with the same number of model parameters. Please discuss why in either case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NFQAPy5w6N2"
      },
      "source": [
        "### 2.0 XOR data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LJ3CxEVTw6N2",
        "outputId": "b480e017-1411-4991-8761-1f65c62b70d3"
      },
      "source": [
        "N=1000 # samples per cluster\n",
        "XY=t.tensor([[5,5],[5,10],[10,5],[10,10]],dtype=t.float32) # 4 cluster centers\n",
        "Z=t.tensor([0,1,1,0]) # category labels\n",
        "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)\n",
        "xy,z=t.zeros(4*N,2),t.zeros(4*N,dtype=t.int64)\n",
        "for i in range(4):\n",
        "    xy[i*N:(i+1)*N,]=t.rand(N,2)+XY[i,]\n",
        "    z[i*N:(i+1)*N]=Z[i]\n",
        "xy_np=xy.numpy()\n",
        "z_np=z.numpy().astype(int)\n",
        "cmap=np.array([[1,0,0],[0,1,0]])\n",
        "scatter(xy_np[:,0],xy_np[:,1],color=cmap[z_np]);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhUCdygXw6N3"
      },
      "source": [
        "#### 2.1 A shallow net with one hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfeCaX_w6N3"
      },
      "source": [
        "# Number of free parameters: 2*H+H*2=48\n",
        "\n",
        "H=12 # number of hidden units\n",
        "model = t.nn.Sequential(\n",
        "    t.nn.Linear(2, H, bias=False),\n",
        "    t.nn.BatchNorm1d(H),\n",
        "    t.nn.ReLU(),\n",
        "    t.nn.Linear(H, 2, bias=False),\n",
        "    t.nn.Softmax(dim=1)\n",
        ")\n",
        "loss_fn = t.nn.CrossEntropyLoss()\n",
        "optimizer = t.optim.Adam(model.parameters())\n",
        "\n",
        "for i in range(100):\n",
        "    z_pred = model(xy)\n",
        "    loss = loss_fn(z_pred,z)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    z_pred = model(xy) \n",
        "    z_pred = t.max(z_pred,1)[1]\n",
        "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA-AlAcuw6N3"
      },
      "source": [
        "#### 2.2 A \"deep\" net with three hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICDHSR5p3Ls5",
        "outputId": "3de0efc3-87b6-44f9-e5a9-c7ae17a8e7ba"
      },
      "source": [
        "\n",
        "print(model.parameters(\"Linear\"))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x7f02ae05f4c0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvGT0X_5w6N3"
      },
      "source": [
        "# Number of free parameters: 2*H+H*H+H*H+H*2=48\n",
        "\n",
        "H=4 # number of hidden units\n",
        "model = t.nn.Sequential(\n",
        "    t.nn.Linear(2, H, bias=False),\n",
        "    t.nn.BatchNorm1d(H),\n",
        "    t.nn.ReLU(),\n",
        "    t.nn.Linear(H, H,bias=False),\n",
        "    t.nn.BatchNorm1d(H),\n",
        "    t.nn.ReLU(),\n",
        "    t.nn.Linear(H, H, bias=False),\n",
        "    t.nn.BatchNorm1d(H),\n",
        "    t.nn.ReLU(),\n",
        "    t.nn.Linear(H, 2, bias=False),\n",
        "    t.nn.Softmax(dim=1)\n",
        ")\n",
        "loss_fn = t.nn.CrossEntropyLoss()\n",
        "optimizer = t.optim.Adam(model.parameters())\n",
        "\n",
        "for i in range(100):\n",
        "    z_pred = model(xy)\n",
        "    loss = loss_fn(z_pred,z)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    z_pred = model(xy) \n",
        "    z_pred = t.max(z_pred,1)[1]\n",
        "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI6d5RYqw6N3"
      },
      "source": [
        "### 2.3 Your answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP94jHu0w6N3"
      },
      "source": [
        "#### 2.3.1 Shallow NN vs. Deep NN 之模擬比較\n",
        "\n",
        "同樣也是方便起見，我將老師的範例程式重新包成一個 class 來執行，但為了比較兩者模型的學習效率，因此我有更改部分的程式碼。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOqG44XZROf7"
      },
      "source": [
        "class XORmodel:\n",
        "  def __init__(self):\n",
        "    self.shallow_times, self.shallow_epochs, self.shallow_accs = None, None, None\n",
        "    self.deep_times, self.deep_epochs, self.deep_accs = None, None, None\n",
        "  \n",
        "  def run_shallow_nn(self, times = 10):\n",
        "    self.shallow_times = times\n",
        "    self.shallow_epochs = np.zeros(times)\n",
        "    self.shallow_accs = np.zeros(times)\n",
        "\n",
        "    for time in range(times):\n",
        "      # Number of free parameters: 2*H+H*2=48\n",
        "      H=12 # number of hidden units\n",
        "      model = t.nn.Sequential(\n",
        "        t.nn.Linear(2, H, bias=False),\n",
        "        t.nn.BatchNorm1d(H),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.Linear(H, 2, bias=False),\n",
        "        t.nn.Softmax(dim=1)\n",
        "      )\n",
        "      loss_fn = t.nn.CrossEntropyLoss()\n",
        "      optimizer = t.optim.Adam(model.parameters())\n",
        "\n",
        "      acc = 0\n",
        "      epoch = 0\n",
        "      while (acc < 1) and (epoch < 500) :\n",
        "        z_pred = model(xy)\n",
        "        loss = loss_fn(z_pred,z)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        z_pred = model(xy) \n",
        "        z_pred = t.max(z_pred,1)[1]\n",
        "        acc = (z_pred==z).sum().item()/xy.shape[0]\n",
        "        epoch += 1\n",
        "      \n",
        "      self.shallow_epochs[time] = epoch\n",
        "      self.shallow_accs[time] = acc\n",
        "\n",
        "\n",
        "  def run_deep_nn(self, times = 10):\n",
        "    self.deep_times = times\n",
        "    self.deep_epochs = np.zeros(times)\n",
        "    self.deep_accs = np.zeros(times)\n",
        "\n",
        "    for time in range(times):\n",
        "      # Number of free parameters: 2*H+H*H+H*H+H*2=48\n",
        "      H=4 # number of hidden units\n",
        "      model = t.nn.Sequential(\n",
        "        t.nn.Linear(2, H, bias=False),\n",
        "        t.nn.BatchNorm1d(H),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.Linear(H, H,bias=False),\n",
        "        t.nn.BatchNorm1d(H),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.Linear(H, H, bias=False),\n",
        "        t.nn.BatchNorm1d(H),\n",
        "        t.nn.ReLU(),\n",
        "        t.nn.Linear(H, 2, bias=False),\n",
        "        t.nn.Softmax(dim=1)\n",
        "      )\n",
        "      loss_fn = t.nn.CrossEntropyLoss()\n",
        "      optimizer = t.optim.Adam(model.parameters())\n",
        "\n",
        "      acc = 0\n",
        "      epoch = 0\n",
        "      while (acc < 1) and (epoch < 500):\n",
        "        z_pred = model(xy)\n",
        "        loss = loss_fn(z_pred,z)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        z_pred = model(xy) \n",
        "        z_pred = t.max(z_pred,1)[1]\n",
        "        acc = (z_pred==z).sum().item()/xy.shape[0]\n",
        "        epoch += 1\n",
        "\n",
        "      self.deep_epochs[time] = epoch\n",
        "      self.deep_accs[time] = acc\n",
        "\n",
        "  def print_result(self):\n",
        "    print(tabulate([['N', self.shallow_times, self.shallow_times, self.deep_times, self.deep_times],\n",
        "            ['N epoch>=500 (acc<1.0)', sum(self.shallow_epochs>=500), sum(self.shallow_epochs>=500), sum(self.deep_epochs>=500), sum(self.deep_epochs>=500)],\n",
        "            ['Min', self.shallow_epochs.min(), self.shallow_accs.min(), self.deep_epochs.min(), self.deep_accs.min()], \n",
        "            ['Mean', self.shallow_epochs.mean(), self.shallow_accs.mean(), self.deep_epochs.mean(), self.deep_accs.mean()],\n",
        "            ['Max', self.shallow_epochs.max(), self.shallow_accs.max(), self.deep_epochs.max(), self.deep_accs.max()],\n",
        "            ['Standard deviaion', self.shallow_epochs.std(), self.shallow_accs.std(), self.deep_epochs.std(), self.deep_accs.std()]], \n",
        "            headers=['Statistic', 'Shallow NN Epoch Number\\n (censoring at 500)', 'Shallow NN Accuracy',  \n",
        "                 'Deep NN Epoch Number\\n (censoring at 500)', 'Deep NN Accuracy'], tablefmt='orgtbl'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukJKnveeJw_0"
      },
      "source": [
        "為了達到公平的判準，我將在 Shallow NN 與 Deep NN 分別跑 50 次，並且記錄每次學習需要多少次 epoch 才能達到準確率 100%，然而我還多加限定最多只能跑到 500 次 epoch，避免浪費太多時間。結果如下\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMiAGvhRTSsO",
        "outputId": "36f3c55b-c227-49c5-acef-baa2674a8688"
      },
      "source": [
        "t.manual_seed(7777)\n",
        "x = XORmodel()\n",
        "x.run_shallow_nn(times = 50)\n",
        "x.run_deep_nn(times = 50)\n",
        "x.print_result()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Statistic              |   Shallow NN Epoch Number |   Shallow NN Accuracy |   Deep NN Epoch Number |   Deep NN Accuracy |\n",
            "|                        |        (censoring at 500) |                       |     (censoring at 500) |                    |\n",
            "|------------------------+---------------------------+-----------------------+------------------------+--------------------|\n",
            "| N                      |                    50     |            50         |                 50     |          50        |\n",
            "| N epoch>=500 (acc<1.0) |                     3     |             3         |                 16     |          16        |\n",
            "| Min                    |                     1     |             0.75      |                 14     |           0.5      |\n",
            "| Mean                   |                   126.96  |             0.993555  |                256.6   |           0.92492  |\n",
            "| Max                    |                   500     |             1         |                500     |           1        |\n",
            "| Standard deviaion      |                   112.903 |             0.0357221 |                182.455 |           0.143573 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3XGwsiNqHg5"
      },
      "source": [
        "從上表觀察中可發現，這兩種模型確實在 XOR 的問題上達到 100% 的準確率。然而就學習效率來說，在同樣的參數數目 (weights 各自都有 48 個且沒有 biaw parameter) 與超參數設定下，Shallow NN 學習的效率快於 Deep NN，前者的平均 epoch 數量比較小 (126.96<256.6) 且就平均準確率也較高 (0.99>0.92)。應該不需要做假設檢定就能發現之間是有明顯差異的\n",
        "\n",
        "雖然說這兩者都有可能迭代到 500 epochs 時準確率依舊還達不到 100%，但在 50 次模擬中， Shallow NN 只有 3 個未完成，而 Deep NN 就有 1/3 次(= 16 次)是失敗的。因此總結來說，Shallow NN 在此問題上要比 Deep NN 來的好。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfgwcuSTMsRc"
      },
      "source": [
        "#### 2.3.2 原因探討：\n",
        "\n",
        "同樣是 XOR 問題，我簡化原本題目給定的設定。假設 $X = (x)_{n \\times 2}\\in \\{0, 1\\}^{n \\times 2}$ 為 input data, $Y = (y)_{n \\times 2} \\in \\{0, 1\\}^{n \\times 2}$ 為 output data。 其中 Shallow NN 與 Deep NN 可以寫成\n",
        "\n",
        "Shallow NN：\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{n \\times 12}Z^{(1)} &= f^{(1)}(\\underset{n \\times 2}X \\, \\underset{2 \\times 12}W^{(1)}) \\\\\n",
        "\\underset{n \\times 2}{Y} &= s(\\underset{n \\times 12}Z^{(1)}\\underset{12 \\times 2}W^{(2)})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Deep NN:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\underset{n \\times 4}Z^{(1)} &= f^{(1)}(\\underset{n \\times 2}X \\, \\underset{2 \\times 4}W^{(1)}) \\\\\n",
        "\\underset{n \\times 4}Z^{(2)} &= f^{(2)}(\\underset{n \\times 4}Z^{(1)}\\underset{4 \\times 4}W^{(2)}) \\\\\n",
        "\\underset{n \\times 4}Z^{(3)} &= f^{(3)}(\\underset{n \\times 4}Z^{(2)}\\underset{4 \\times 4}W^{(3)}) \\\\\n",
        "\\underset{n \\times 2}Y &= s(\\underset{n \\times 4}Z^{(3)}\\underset{4 \\times 4}W^{(4)})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "其中 $Z$ 為隱藏層的輸出，$f_1(.), f_2(.), f_3()$ 皆為 ReLU function, $s(.)$ 為 softmax function。實際上這兩個模型可再寫為\n",
        "\n",
        "Shallow NN:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "Y &= g(X) = g(x_1, x_2) \\\\\n",
        "&= s\\left(\\sum_{j=1}^{12} w_j^{(2)} \\times f_{j}^{(1)}(\\sum_{i=2}^2 w_{ji}^{(1)}x_i)\\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Deep NN:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "Y &= g'(X) = g'(x_1, x_2) \\\\\n",
        "&= s\\left(\\sum_{l=1}^{4} w_{l}^{(4)} \\times f_{l}^{(3)}(\\sum_{k=1}^{4} w_{lk}^{(3)} \\times f_{k}^{(2)}(\\sum_{j=1}^{4} w_{kj}^{(2)}\\times f_{j}^{(1)}(\\sum_{i=2}^2 w_{ji}^{(1)}x_i)))\\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "雖然寫的「落落長」，但我想表達的是這兩種神經網路模型，其實在做的就是要去估計 $X$ 和 $Y$ 之間的對應關係，也就是上式中的 $g: X \\mapsto Y$ 和 $g': X \\mapsto Y$。若我們先忽略掉 softmax function 和 batch normalized 的部分，兩者之間的差異在於 shallow NN 中的 $X$ 只經過一次的非線性的轉換，而 deep NN 中的 $X$ 卻經過三次的非線性轉換。我們可以想像 deep NN 應該能比 shallow NN 更可以描繪出更複雜的 $X$ 之間的關係，例如 $X$ 之間的交互作用或是高次項...等，因此很容易去建立 $X$ $Y$ 之間複雜的函數關係，這也是為何現今大家比較偏好 deep NN 的原因之一(ref: https://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network-and-w)。\n",
        "\n",
        "然而其代價就是，deep NN 面對較簡易的情境，像是這次的 XOR 分類問題，太複雜的模型結構 (一堆非線性轉換) 可能會使得學習效率較差，參數在迭代更新時可能落入區域極值，或是需要較長的時間將複雜的數學形式轉回簡單的對應關係。反而不像 shallow NN 要來的簡單明瞭，因此，在這此作業中可以發現 shallow NN 會學得比較快。當然，如果參數以及學習時間充裕的話，根據 Universal approximation theorem，兩者應該都能學得很好。\n",
        "\n",
        "Shallow NN 圖示範例：\n",
        "\n",
        "<img src=\"https://github.com/xup6y3ul6/Neural-and-Behavioral-Modeling/blob/main/12_Deep-learning%20Neural%20Networks%20(2-4)%20Convolutional%20Neural%20Network%20(CNN)/snn.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "\n",
        "Deep NN 圖示範例：(可以注意三層隱藏層，其對 $X$ 的表徵越來越複雜)\n",
        "\n",
        "<img src=\"https://github.com/xup6y3ul6/Neural-and-Behavioral-Modeling/blob/main/12_Deep-learning%20Neural%20Networks%20(2-4)%20Convolutional%20Neural%20Network%20(CNN)/dnn.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "Deep NN 圖示失敗範例：\n",
        "\n",
        "<img src=\"https://github.com/xup6y3ul6/Neural-and-Behavioral-Modeling/blob/main/12_Deep-learning%20Neural%20Networks%20(2-4)%20Convolutional%20Neural%20Network%20(CNN)/dnn_fail.png?raw=true\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "可參考下方網站模擬：\n",
        "\n",
        "- [A Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.83918&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) $\\leftarrow\\leftarrow$ 感謝劉昱維介紹！\n",
        "- [Neural Network demo — Preset: Binary Classifier for XOR](https://phiresky.github.io/neural-network-demo/)\n",
        "\n"
      ]
    }
  ]
}